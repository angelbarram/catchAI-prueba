# CatchAI - Copiloto Conversacional sobre Documentos

## ğŸ¯ DescripciÃ³n del Proyecto

Copiloto conversacional que permite subir hasta 5 archivos PDF y hacer preguntas en lenguaje natural sobre su contenido. Utiliza RAG (Retrieval Augmented Generation) con orquestaciÃ³n clara y extensible.

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚    Backend       â”‚    â”‚   Vector Store  â”‚
â”‚   (Streamlit)   â”‚â—„â”€â”€â–ºâ”‚   (FastAPI)      â”‚â—„â”€â”€â–ºâ”‚    (Chroma)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   LLM Provider   â”‚
                       â”‚   (OpenAI GPT)   â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes principales:

1. **Procesamiento de Documentos**: ExtracciÃ³n, chunking y vectorizaciÃ³n de PDFs
2. **Vector Store**: Almacenamiento de embeddings para bÃºsqueda semÃ¡ntica
3. **Motor de ConversaciÃ³n**: OrquestaciÃ³n de prompts y manejo del contexto
4. **Interfaz de Usuario**: Frontend interactivo con Streamlit
5. **API Backend**: FastAPI para endpoints RESTful

## ğŸ› ï¸ Stack TecnolÃ³gico

- **OrquestaciÃ³n**: LangChain para RAG y chain management
- **LLM**: OpenAI GPT-4o-mini (cost-effective y potente)
- **Vector Store**: ChromaDB (fÃ¡cil setup, persistent)
- **PDF Processing**: PyPDF2 + LangChain document loaders
- **Embeddings**: OpenAI text-embedding-3-small
- **Frontend**: Streamlit (rÃ¡pido desarrollo, UX intuitiva)
- **Backend**: FastAPI (opcional, para arquitectura modular)
- **ContainerizaciÃ³n**: Docker + docker-compose

## ğŸš€ Instrucciones de InstalaciÃ³n

### OpciÃ³n 1: Docker (Recomendado)

```bash
# Clonar el repositorio
git clone <repository-url>
cd catchai_prueba_tecnica

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tu OPENAI_API_KEY

# Levantar el entorno
docker-compose up -d

# Acceder a la aplicaciÃ³n
# Frontend: http://localhost:8501
# API Docs: http://localhost:8000/docs
```

### OpciÃ³n 2: InstalaciÃ³n Local

```bash
# Crear entorno virtual
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# Instalar dependencias
pip install -r requirements.txt

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tu OPENAI_API_KEY

# Ejecutar la aplicaciÃ³n
streamlit run src/frontend/app.py
```

## ğŸ”„ Flujo Conversacional

### 1. Carga de Documentos
- Usuario sube hasta 5 PDFs
- ExtracciÃ³n de texto con PyPDF2
- Chunking inteligente (1000 tokens, overlap 200)
- GeneraciÃ³n de embeddings
- Almacenamiento en ChromaDB

### 2. Procesamiento de Consultas
```
Consulta Usuario â†’ Embedding â†’ BÃºsqueda SemÃ¡ntica â†’ Contexto Relevante â†’ LLM â†’ Respuesta
```

### 3. OrquestaciÃ³n de Prompts
- **System Prompt**: Define el rol del asistente
- **Context Prompt**: Inyecta documentos relevantes
- **User Prompt**: Pregunta del usuario
- **Memory**: Mantiene historial conversacional

## ğŸ’¡ Funcionalidades Implementadas

### âœ… Requisitos MÃ­nimos
- [x] Subida de hasta 5 PDFs
- [x] ExtracciÃ³n y vectorizaciÃ³n de contenido
- [x] Interfaz conversacional
- [x] OrquestaciÃ³n estructurada y extensible

### ğŸŒŸ Funcionalidades Adicionales
- [x] Resumen automÃ¡tico de documentos
- [x] Comparaciones entre documentos
- [x] ClasificaciÃ³n por temas
- [x] Historial de conversaciÃ³n
- [x] MÃ©tricas de relevancia
- [x] Interfaz responsive

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno (.env)
```
OPENAI_API_KEY=tu_api_key_aqui
CHROMA_PERSIST_DIR=./data/chroma_db
MAX_FILES=5
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
```

## ğŸ“ Estructura del Proyecto

```
catchai_prueba_tecnica/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”œâ”€â”€ frontend/
â”‚   â”‚   â””â”€â”€ app.py
â”‚   â””â”€â”€ shared/
â”‚       â”œâ”€â”€ config/
â”‚       â”œâ”€â”€ models/
â”‚       â””â”€â”€ utils/
â”œâ”€â”€ data/
â”œâ”€â”€ tests/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ® Casos de Uso

1. **AnÃ¡lisis de Documentos**: "Resume los puntos principales de todos los documentos"
2. **BÃºsqueda EspecÃ­fica**: "Â¿QuÃ© dice sobre inteligencia artificial?"
3. **Comparaciones**: "Â¿CuÃ¡les son las diferencias entre el documento 1 y 3?"
4. **ExtracciÃ³n de Datos**: "Lista todas las fechas mencionadas"

## ğŸš§ Limitaciones Actuales

- MÃ¡ximo 5 PDFs por sesiÃ³n
- Solo texto (no imÃ¡genes ni tablas complejas)
- Contexto limitado por window del LLM
- Dependencia de OpenAI API

## ğŸ›£ï¸ Roadmap de Mejoras

### Corto Plazo
- [ ] Soporte para mÃ¡s formatos (DOCX, TXT)
- [ ] Procesamiento de imÃ¡genes y tablas (OCR)
- [ ] Cache de embeddings para optimizaciÃ³n

### Mediano Plazo
- [ ] MÃºltiples LLM providers (Claude, Llama)
- [ ] BÃºsqueda hÃ­brida (semÃ¡ntica + keyword)
- [ ] ExportaciÃ³n de conversaciones

### Largo Plazo
- [ ] ColaboraciÃ³n multi-usuario
- [ ] IntegraciÃ³n con APIs externas
- [ ] Fine-tuning de modelos especÃ­ficos

## ğŸ§ª Testing

```bash
# Ejecutar tests
python -m pytest tests/ -v

# Coverage report
python -m pytest tests/ --cov=src --cov-report=html
```

## ğŸ“ˆ MÃ©tricas y Monitoreo

- Tiempo de respuesta de consultas
- PrecisiÃ³n de bÃºsqueda semÃ¡ntica
- Uso de tokens y costos
- SatisfacciÃ³n del usuario

---

**Desarrollado por**: [Tu Nombre]  
**Para**: CatchAI Technical Challenge  
**Fecha**: Agosto 2025
